# 3.2. 3D Reconstruction Pipeline

This section details the algorithms and implementation of the 3D reconstruction process in Brush.

## 3.2.1. Conceptual Overview

Brush performs 3D reconstruction using the **3D Gaussian Splatting (GS)** technique, introduced in the paper [3D Gaussian Splatting for Real-Time Radiance Field Rendering](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/). This approach represents a 3D scene as a collection of millions of 3D Gaussians, each defined by parameters like position, shape (covariance/scale+rotation), color (represented by Spherical Harmonics), and opacity.

The general GS process, which Brush follows, involves:

1.  **Input:** A set of images of a scene with known camera poses, typically obtained from Structure-from-Motion (SfM) software like COLMAP.
2.  **Initialization:** Creating an initial set of 3D Gaussians. This often starts from the sparse point cloud generated by SfM.
3.  **Optimization:** Iteratively rendering the current set of Gaussians from the known camera viewpoints using a differentiable renderer. The difference (loss) between the rendered image and the corresponding ground truth input image is calculated. This loss is then backpropagated to compute gradients for all Gaussian parameters.
4.  **Parameter Update:** An optimizer (commonly Adam) uses the gradients to update the position, shape, color, and opacity of each Gaussian, aiming to minimize the rendering loss.
5.  **Adaptive Density Control (ADC):** Periodically adjusting the number of Gaussians during optimization. Gaussians are typically *densified* (split or cloned) in areas that are poorly reconstructed (indicated by high gradients or large Gaussian size) and *pruned* (removed) if they become essentially invisible (low opacity) or too large.
6.  **Output:** The final optimized set of 3D Gaussians, representing the captured scene, usually stored in a `.ply` file.

Brush implements this process using the [Burn](core-technologies.md#343-burn) framework with custom WGSL kernels for GPU acceleration.

## 3.2.2. Brush Reconstruction Algorithm Details

Brush specifically implements the optimization phase of the 3D Gaussian Splatting pipeline. It does not perform the initial SfM step itself but relies on input formats like COLMAP or Nerfstudio which provide pre-computed camera poses.

Key aspects of Brush's implementation (primarily within the `brush-train` and `brush-process` crates) include:

*   **Initialization:**
    *   If the input dataset (e.g., from COLMAP) contains a sparse point cloud (`points3D.txt` or `points3D.bin`), Brush uses these points to initialize the positions and colors of the initial Gaussians.
    *   If no initial point cloud is found, Brush initializes Gaussians randomly within the scene bounds derived from the input camera poses.
*   **Optimization Loop:**
    *   **Loss Function:** By default, Brush minimizes a combined loss function consisting of L1 pixel difference and SSIM (Structural Similarity Index Measure) between the rendered and ground truth images. The balance is controlled by `--ssim-weight` (default 0.2). An optional opacity regularization term (`--opac-loss-weight`) can be added, decaying over time.
    *   **Optimizer:** Brush uses a custom Adam optimizer (`AdamScaled` in `brush-train/src/adam_scaled.rs`) with separate, exponentially decaying learning rate schedules for different parameter groups (position, rotation, scale, opacity, SH coefficients). These learning rates can be configured via command-line arguments (e.g., `--lr-mean`, `--lr-scale`, `--lr-rotation`, etc.).
    *   **Differentiable Rendering:** The optimization relies on the differentiable forward rendering pass provided by `brush-render` and the corresponding backward pass implemented in `brush-render-bwd`, utilizing custom WGSL kernels.
*   **Adaptive Density Control (ADC):** Performed periodically based on the `--refine-every` parameter.
    *   **Pruning:** Gaussians with opacity below a fixed threshold (`MIN_OPACITY` constant in `brush-train`) are removed.
    *   **Densification (Cloning):** Gaussians exhibiting high view-space position gradients (above `--growth-grad-threshold`) are identified. A fraction (`--growth-select-fraction`) of these are cloned, with the clones receiving reduced scale and adjusted opacity. Replacement points for pruned Gaussians are also generated by sampling existing high-opacity Gaussians. Densification stops after `--growth-stop-iter` training steps.

Compared to other open-source implementations like [gsplat](https://github.com/nerfstudio-project/gsplat) which often rely on custom CUDA kernels, Brush's key distinction is its implementation using Rust, the Burn framework, and WGSL for cross-platform GPU acceleration.

## 3.2.3. Implementation Details

The reconstruction pipeline involves tight interaction between several core crates:

*   **`brush-process` (`train_stream.rs`)**: Orchestrates the overall training process. It initializes the dataset loader, the trainer, and runs the main loop, handling data loading, training steps, evaluation, and export.
*   **`brush-dataset` (`scene_loader.rs`, `scene.rs`, `formats/`)**: Loads the input data (images, camera poses, potentially initial points) according to the specified format (COLMAP, Nerfstudio). It provides batches of training data (`SceneBatch`) to the trainer.
*   **`brush-train` (`train.rs`)**: Contains the `SplatTrainer` struct, which implements the main optimization logic:
    *   Receives training batches from `brush-dataset`.
    *   Invokes the differentiable renderer (`brush-render`, `brush-render-bwd`) to get the current view and gradients.
    *   Calculates the loss (L1 + SSIM).
    *   Uses the `AdamScaled` optimizer to update Gaussian parameters.
    *   Performs the Adaptive Density Control (pruning and densification).
*   **`brush-render` (`gaussian_splats.rs`, `render.rs`)**: Defines the `Splats` struct holding Gaussian parameters and implements the forward rendering pass necessary for calculating the loss.
*   **`brush-render-bwd` (`burn_glue.rs`, `kernels.rs`)**: Implements the backward pass for the renderer, enabling gradient calculation through the rendering process.
*   **Burn Framework (`burn-rs`)**: Underpins the entire ML process:
    *   Provides the tensor structures (`Tensor`) used to store Gaussian parameters (`Splats` uses `Param<Tensor<...>>`).
    *   Manages computation on the target device via the `Wgpu` backend.
    *   Supplies the automatic differentiation engine (`Autodiff<Wgpu>`) essential for backpropagating the loss through the renderer.
    *   Offers the basic optimizer (`AdamScaled`) adapted for Brush's needs.

**Key Data Structures:**

*   **`brush_render::gaussian_splats::Splats<B: Backend>`**: Central structure holding all optimizable Gaussian parameters (means, log_scales, rotation, sh_coeffs, raw_opacity) as Burn `Param<Tensor<...>>`.
*   **`brush_dataset::Dataset`**: Represents the entire dataset, containing training (`Scene`) and potentially evaluation (`Option<Scene>`) views.
*   **`brush_dataset::scene::Scene`**: A collection of camera views (`SceneView`) for a specific split (train/eval), along with scene-level metadata like bounds.
*   **`brush_dataset::scene::SceneView`**: Holds the data for a single viewpoint, including the `Camera` parameters and the ground truth `LoadImage`.
*   **`brush_render::camera::Camera`**: Stores camera intrinsics (FoV, principal point) and extrinsics (position, rotation).
*   **`brush_dataset::scene::SceneBatch<B: Backend>`**: Contains the data required for a single training step, typically including a batch of `Camera` objects and corresponding ground truth image `Tensor`s loaded onto the GPU.

*(Note: Many of these values, such as splat counts, training step, steps/s, and evaluation results, are displayed live in the `Stats` panel in the UI.)*

## 3.2.4. Configuration

The training process can be configured through various command-line options when running `brush_app`. Key parameters influencing the reconstruction include:

*   **General Training:**
    *   `--total-steps <N>`: Total optimization iterations.
    *   `--ssim-weight <W>`: Balance between L1 and SSIM loss (default: 0.2).
*   **Learning Rates:**
    *   `--lr-mean <LR>`, `--lr-mean-end <LR>`: Learning rate for Gaussian positions (xyz).
    *   `--lr-coeffs-dc <LR>`, `--lr-coeffs-sh-scale <S>`: Learning rates for Spherical Harmonic coefficients (color).
    *   `--lr-opac <LR>`: Learning rate for opacity.
    *   `--lr-scale <LR>`, `--lr-scale-end <LR>`: Learning rate for Gaussian scale.
    *   `--lr-rotation <LR>`: Learning rate for Gaussian rotation.
*   **Regularization/Loss:**
    *   `--opac-loss-weight <W>`: Weight for opacity regularization loss.
    *   `--mean-noise-weight <W>`: Controls noise added to low-opacity Gaussians.
    *   `--match-alpha-weight <W>`: Weight for matching input image transparency.
*   **Adaptive Density Control (Refinement):**
    *   `--refine-every <N>`: Frequency (in steps) of densification/pruning.
    *   `--growth-grad-threshold <T>`: Gradient threshold for triggering densification.
    *   `--growth-select-fraction <F>`: Fraction of eligible Gaussians to actually densify.
    *   `--growth-stop-iter <N>`: Iteration after which densification stops.
*   **Model:**
    *   `--sh-degree <D>`: Degree of Spherical Harmonics used for view-dependent color (default: 3).
    *   `--max-splats <N>`: Hard upper limit on the number of Gaussians.
*   **Dataset:**
    *   `--max-frames <N>`, `--max-resolution <R>`, `--subsample-frames <N>`: Control dataset size/resolution.

*(Note: Default values are listed in the `--help` output. These parameters can significantly impact training time and final quality.)*

---

## Where to Go Next?

*   Understand how the scene is rendered: **[Rendering Pipeline](rendering-pipeline.md)**.
*   See the high-level project structure: **[Architecture Overview](architecture.md)**.
*   Learn about the ML framework used: **[Burn in Core Technologies](core-technologies.md#343-burn)**.
*   Try running it: **[User Guide](../getting-started/user-guide.md)**. 