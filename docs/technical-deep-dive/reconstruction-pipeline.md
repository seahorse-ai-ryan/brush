# 3.2. 3D Reconstruction Pipeline

This section details the algorithms and implementation of the 3D reconstruction process in Brush.

## 3.2.1. Conceptual Overview

Brush performs 3D reconstruction using the **3D Gaussian Splatting** technique. Unlike traditional mesh-based or volumetric methods (like NeRF), Gaussian Splatting represents the scene as a collection of 3D Gaussians.

The core idea is to optimize the parameters (position, shape, color, opacity) of these Gaussians directly, typically starting from sparse points generated by Structure from Motion (SfM).

The process generally involves:

1.  **Input:** Posed images (camera parameters known) from a format like COLMAP or Nerfstudio.
2.  **Initialization:** Often starts with a sparse point cloud derived from SfM (possibly generated externally or by COLMAP itself).
3.  **Optimization:** Iteratively render the Gaussians from the training camera viewpoints and compare the result to the ground truth images. The differences (loss) are used to update the Gaussian parameters (position, covariance, color, opacity) via gradient descent. This involves a differentiable renderer.
4.  **Adaptive Density Control:** During optimization, Gaussians are periodically densified (split or cloned) in areas with large reconstruction errors and pruned (removed) if they are transparent or excessively large.
5.  **Output:** A set of optimized 3D Gaussians representing the scene, typically saved as a `.ply` file.

## 3.2.2. Algorithm(s)

Brush implements the **3D Gaussian Splatting** algorithm, as introduced in the paper:

*   **[3D Gaussian Splatting for Real-Time Radiance Field Rendering](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/)** by Kerbl et al. (SIGGRAPH 2023)

*(TODO: Verify if Brush implements specific variations or additions to the original algorithm based on code analysis of `brush-train`.)*

The implementation relies heavily on a differentiable rendering pipeline (covered in the [Gaussian Splat Rendering](gaussian-splatting.md) section) and optimization driven by the [Burn](core-technologies.md#343-burn) framework.

## 3.2.3. Implementation Details

The core reconstruction logic resides primarily within the `brush-train` crate.

*   **Burn Usage:** The [Burn](core-technologies.md#343-burn) framework is used for:
    *   Defining the optimizable parameters (Gaussians).
    *   Calculating losses between rendered images and training images.
    *   Performing automatic differentiation to get gradients.
    *   Applying optimizers (e.g., Adam) to update Gaussian parameters.
    *   Leveraging the `wgpu` backend for GPU acceleration.
*   **Crate Roles:**
    *   `brush-dataset`: Provides the input posed images and camera parameters.
    *   `brush-process`: May handle initial loading and any necessary preprocessing.
    *   `brush-train`: Orchestrates the optimization loop.
    *   `brush-render` / `brush-render-bwd`: Provide the differentiable rendering mechanism.
    *   `brush-kernel` / `brush-sort` / etc.: Provide GPU-accelerated primitives used by the renderer and potentially the optimizer.
*   **Data Structures:** *(TODO: Identify and describe key Rust structs representing Gaussians, datasets, camera parameters within `brush-dataset` and `brush-train`.)*

## 3.2.4. Configuration

The training process can be configured through various command-line options when running `brush_app`. Key parameters influencing the reconstruction include:

*   **General Training:**
    *   `--total-steps <N>`: Total optimization iterations.
    *   `--ssim-weight <W>`: Balance between L1 and SSIM loss (default: 0.2).
*   **Learning Rates:**
    *   `--lr-mean <LR>`, `--lr-mean-end <LR>`: Learning rate for Gaussian positions (xyz).
    *   `--lr-coeffs-dc <LR>`, `--lr-coeffs-sh-scale <S>`: Learning rates for Spherical Harmonic coefficients (color).
    *   `--lr-opac <LR>`: Learning rate for opacity.
    *   `--lr-scale <LR>`, `--lr-scale-end <LR>`: Learning rate for Gaussian scale.
    *   `--lr-rotation <LR>`: Learning rate for Gaussian rotation.
*   **Regularization/Loss:**
    *   `--opac-loss-weight <W>`: Weight for opacity regularization loss.
    *   `--mean-noise-weight <W>`: Controls noise added to low-opacity Gaussians.
    *   `--match-alpha-weight <W>`: Weight for matching input image transparency.
*   **Adaptive Density Control (Refinement):**
    *   `--refine-every <N>`: Frequency (in steps) of densification/pruning.
    *   `--growth-grad-threshold <T>`: Gradient threshold for triggering densification.
    *   `--growth-select-fraction <F>`: Fraction of eligible Gaussians to actually densify.
    *   `--growth-stop-iter <N>`: Iteration after which densification stops.
*   **Model:**
    *   `--sh-degree <D>`: Degree of Spherical Harmonics used for view-dependent color (default: 3).
    *   `--max-splats <N>`: Hard upper limit on the number of Gaussians.
*   **Dataset:**
    *   `--max-frames <N>`, `--max-resolution <R>`, `--subsample-frames <N>`: Control dataset size/resolution.

*(Note: Default values are listed in the `--help` output. These parameters can significantly impact training time and final quality.)* 